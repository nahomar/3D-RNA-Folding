{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford RNA 3D Folding - Full Pipeline Submission\n",
    "\n",
    "**Implements the 14-Day Hybrid Expert Plan:**\n",
    "1. Template Search (MMseqs2)\n",
    "2. RhoFold+ Predictions (with multiple seeds)\n",
    "3. DRfold2 Ab Initio Predictions\n",
    "4. Energy Minimization (OpenMM)\n",
    "5. Diverse Ensemble Selection\n",
    "\n",
    "**Requirements:** Kaggle GPU (T4/P100 minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q einops biopython ml-collections dm-tree tqdm pyyaml scipy\n",
    "!pip install -q openmm pdbfixer\n",
    "!apt-get install -qq mmseqs2 > /dev/null 2>&1\n",
    "print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repositories\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('predictions', exist_ok=True)\n",
    "os.makedirs('templates', exist_ok=True)\n",
    "os.makedirs('relaxed', exist_ok=True)\n",
    "\n",
    "# RhoFold+\n",
    "if not os.path.exists('models/RhoFold'):\n",
    "    !git clone --quiet https://github.com/ml4bio/RhoFold.git models/RhoFold\n",
    "    %cd models/RhoFold\n",
    "    !pip install -q -e .\n",
    "    %cd ../..\n",
    "\n",
    "# DRfold2\n",
    "if not os.path.exists('models/DRfold2'):\n",
    "    !git clone --quiet https://github.com/leeyang/DRfold2.git models/DRfold2\n",
    "\n",
    "print(\"Repositories ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model weights\n",
    "!mkdir -p models/RhoFold/pretrained\n",
    "if not os.path.exists('models/RhoFold/pretrained/RhoFold_pretrained.pt'):\n",
    "    !wget -q https://huggingface.co/cuhkaih/rhofold/resolve/main/rhofold_pretrained_params.pt \\\n",
    "        -O models/RhoFold/pretrained/RhoFold_pretrained.pt\n",
    "    print(\"RhoFold+ weights downloaded\")\n",
    "\n",
    "# DRfold2 weights\n",
    "%cd models/DRfold2\n",
    "!bash install.sh 2>/dev/null || echo \"Note: DRfold2 setup may need adjustments\"\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Load data\n",
    "test_seqs = pd.read_csv('/kaggle/input/stanford-rna-3d-folding-2/test_sequences.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/stanford-rna-3d-folding-2/sample_submission.csv')\n",
    "print(f\"\\nTest sequences: {len(test_seqs)}\")\n",
    "print(f\"Submission rows: {len(sample_sub)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Template Search (MMseqs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Create FASTA for test sequences\n",
    "with open('templates/test.fasta', 'w') as f:\n",
    "    for _, row in test_seqs.iterrows():\n",
    "        f.write(f\">{row['target_id']}\\n{row['sequence']}\\n\")\n",
    "\n",
    "# Download PDB sequences\n",
    "!wget -q https://files.rcsb.org/pub/pdb/derived_data/pdb_seqres.txt.gz -O templates/pdb.txt.gz\n",
    "!gunzip -f templates/pdb.txt.gz\n",
    "\n",
    "# Extract RNA\n",
    "with open('templates/pdb.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "rna_count = 0\n",
    "with open('templates/pdb_rna.fasta', 'w') as out:\n",
    "    for entry in content.split('>')[1:]:\n",
    "        lines = entry.strip().split('\\n')\n",
    "        if len(lines) < 2:\n",
    "            continue\n",
    "        header = lines[0]\n",
    "        seq = ''.join(lines[1:]).upper().replace('T', 'U')\n",
    "        if re.match('^[ACGU]+$', seq) and len(seq) >= 10:\n",
    "            out.write(f'>{header.split()[0]}\\n{seq}\\n')\n",
    "            rna_count += 1\n",
    "\n",
    "print(f\"Extracted {rna_count} RNA sequences\")\n",
    "\n",
    "# Run MMseqs2\n",
    "!mmseqs easy-search templates/test.fasta templates/pdb_rna.fasta \\\n",
    "    templates/hits.m8 templates/tmp \\\n",
    "    --search-type 3 -e 1e-3 -s 7.5 --threads 4 \\\n",
    "    --format-output \"query,target,pident,evalue\" 2>/dev/null\n",
    "\n",
    "# Parse results\n",
    "if os.path.exists('templates/hits.m8') and os.path.getsize('templates/hits.m8') > 0:\n",
    "    hits = pd.read_csv('templates/hits.m8', sep='\\t', header=None,\n",
    "                       names=['query', 'target', 'pident', 'evalue'])\n",
    "    best_templates = hits.loc[hits.groupby('query')['pident'].idxmax()]\n",
    "    print(f\"Found templates for {len(best_templates)} targets\")\n",
    "    print(best_templates.head())\n",
    "else:\n",
    "    best_templates = pd.DataFrame()\n",
    "    print(\"No templates found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: RhoFold+ Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'models/RhoFold')\n",
    "\n",
    "# Fix OpenMM imports\n",
    "rhofold_relax = Path('models/RhoFold/rhofold/relax/relax.py')\n",
    "if rhofold_relax.exists():\n",
    "    content = rhofold_relax.read_text()\n",
    "    if 'from simtk.openmm' in content and 'try:' not in content[:300]:\n",
    "        content = content.replace(\n",
    "            'from simtk.openmm.app import *\\nfrom simtk.openmm import *\\nfrom simtk.unit import *\\nimport simtk.openmm as mm',\n",
    "            '''try:\\n    from simtk.openmm.app import *\\n    from simtk.openmm import *\\n    from simtk.unit import *\\n    import simtk.openmm as mm\\nexcept ImportError:\\n    from openmm.app import *\\n    from openmm import *\\n    from openmm.unit import *\\n    import openmm as mm'''\n",
    "        )\n",
    "        rhofold_relax.write_text(content)\n",
    "\n",
    "from rhofold.rhofold import RhoFold\n",
    "from rhofold.config import rhofold_config\n",
    "from rhofold.utils.alphabet import Alphabet\n",
    "\n",
    "# Load model\n",
    "config = rhofold_config()\n",
    "rhofold_model = RhoFold(config)\n",
    "ckpt = torch.load('models/RhoFold/pretrained/RhoFold_pretrained.pt', map_location='cpu', weights_only=False)\n",
    "rhofold_model.load_state_dict(ckpt['model'])\n",
    "rhofold_model = rhofold_model.to(device).eval()\n",
    "print(\"RhoFold+ loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rhofold(target_id, sequence, seeds=[42, 123, 456, 789, 1234]):\n",
    "    \"\"\"Run RhoFold+ with multiple seeds for diversity.\"\"\"\n",
    "    alphabet = Alphabet.get_default()\n",
    "    predictions = []\n",
    "    \n",
    "    if len(sequence) > 1000:\n",
    "        print(f\"  Skipping {target_id} - too long ({len(sequence)} nt)\")\n",
    "        return predictions\n",
    "    \n",
    "    tokens = torch.tensor([[alphabet.get_idx(c) for c in sequence]]).to(device)\n",
    "    \n",
    "    for seed in seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed(seed)\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = rhofold_model(\n",
    "                    tokens=tokens,\n",
    "                    rna_fm_tokens=tokens.clone(),\n",
    "                    seq=sequence\n",
    "                )\n",
    "            \n",
    "            coords = outputs['cord_tns_pred'][-1][0].cpu().numpy()\n",
    "            c1_prime = coords[:, 1, :]  # C1' atom\n",
    "            \n",
    "            predictions.append({\n",
    "                'seed': seed,\n",
    "                'coords': c1_prime,\n",
    "                'source': 'rhofold'\n",
    "            })\n",
    "        except Exception as e:\n",
    "            if 'out of memory' in str(e).lower():\n",
    "                print(f\"  OOM at seed {seed}\")\n",
    "                torch.cuda.empty_cache()\n",
    "                break\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Run predictions\n",
    "rhofold_predictions = {}\n",
    "for idx, row in tqdm(test_seqs.iterrows(), total=len(test_seqs), desc=\"RhoFold+\"):\n",
    "    preds = run_rhofold(row['target_id'], row['sequence'])\n",
    "    if preds:\n",
    "        rhofold_predictions[row['target_id']] = preds\n",
    "\n",
    "print(f\"\\nRhoFold+ completed: {len(rhofold_predictions)} targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: DRfold2 Ab Initio (for difficult targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_drfold2(target_id, sequence):\n",
    "    \"\"\"Run DRfold2 ab initio prediction.\"\"\"\n",
    "    os.makedirs(f'predictions/drfold2/{target_id}', exist_ok=True)\n",
    "    fasta_path = f'predictions/drfold2/{target_id}/input.fasta'\n",
    "    \n",
    "    with open(fasta_path, 'w') as f:\n",
    "        f.write(f'>{target_id}\\n{sequence}\\n')\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['python', 'models/DRfold2/DRfold2.py',\n",
    "             '-i', fasta_path,\n",
    "             '-o', f'predictions/drfold2/{target_id}',\n",
    "             '--device', device],\n",
    "            capture_output=True, text=True, timeout=300\n",
    "        )\n",
    "        pdb_path = f'predictions/drfold2/{target_id}/pred.pdb'\n",
    "        if os.path.exists(pdb_path):\n",
    "            return pdb_path\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# Run DRfold2 on targets without RhoFold+ predictions or low-confidence\n",
    "drfold2_predictions = {}\n",
    "missing_targets = [t for t in test_seqs['target_id'] if t not in rhofold_predictions]\n",
    "short_missing = [t for t in missing_targets \n",
    "                 if len(test_seqs[test_seqs['target_id']==t]['sequence'].values[0]) <= 500]\n",
    "\n",
    "print(f\"Running DRfold2 on {len(short_missing)} missing targets\")\n",
    "\n",
    "for target_id in tqdm(short_missing, desc=\"DRfold2\"):\n",
    "    seq = test_seqs[test_seqs['target_id']==target_id]['sequence'].values[0]\n",
    "    pdb_path = run_drfold2(target_id, seq)\n",
    "    if pdb_path:\n",
    "        drfold2_predictions[target_id] = pdb_path\n",
    "\n",
    "print(f\"DRfold2 completed: {len(drfold2_predictions)} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Energy Minimization (OpenMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from openmm.app import *\n",
    "    from openmm import *\n",
    "    from openmm.unit import *\n",
    "except ImportError:\n",
    "    from simtk.openmm.app import *\n",
    "    from simtk.openmm import *\n",
    "    from simtk.unit import *\n",
    "\n",
    "from pdbfixer import PDBFixer\n",
    "\n",
    "def coords_to_pdb(coords, sequence, output_path):\n",
    "    \"\"\"Convert coordinates to PDB.\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        for i, (coord, res) in enumerate(zip(coords, sequence)):\n",
    "            x, y, z = coord\n",
    "            f.write(f\"ATOM  {i+1:5d}  C1' {res:3s} A{i+1:4d}    \"\n",
    "                    f\"{x:8.3f}{y:8.3f}{z:8.3f}  1.00 50.00           C\\n\")\n",
    "        f.write(\"END\\n\")\n",
    "\n",
    "def energy_minimize(pdb_path, output_path, max_iter=200):\n",
    "    \"\"\"Run OpenMM energy minimization.\"\"\"\n",
    "    try:\n",
    "        fixer = PDBFixer(filename=pdb_path)\n",
    "        fixer.findMissingResidues()\n",
    "        fixer.findMissingAtoms()\n",
    "        fixer.addMissingAtoms()\n",
    "        \n",
    "        forcefield = ForceField('amber14-all.xml', 'implicit/gbn2.xml')\n",
    "        system = forcefield.createSystem(fixer.topology, nonbondedMethod=NoCutoff)\n",
    "        integrator = LangevinMiddleIntegrator(300*kelvin, 1/picosecond, 0.002*picoseconds)\n",
    "        simulation = Simulation(fixer.topology, system, integrator)\n",
    "        simulation.context.setPositions(fixer.positions)\n",
    "        simulation.minimizeEnergy(maxIterations=max_iter)\n",
    "        \n",
    "        positions = simulation.context.getState(getPositions=True).getPositions()\n",
    "        with open(output_path, 'w') as f:\n",
    "            PDBFile.writeFile(simulation.topology, positions, f)\n",
    "        return True\n",
    "    except:\n",
    "        import shutil\n",
    "        shutil.copy(pdb_path, output_path)\n",
    "        return False\n",
    "\n",
    "# Minimize predictions\n",
    "minimized = {}\n",
    "for target_id, preds in tqdm(rhofold_predictions.items(), desc=\"Minimizing\"):\n",
    "    seq = test_seqs[test_seqs['target_id']==target_id]['sequence'].values[0]\n",
    "    minimized[target_id] = []\n",
    "    \n",
    "    for pred in preds:\n",
    "        pdb_path = f\"predictions/{target_id}_s{pred['seed']}.pdb\"\n",
    "        relax_path = f\"relaxed/{target_id}_s{pred['seed']}.pdb\"\n",
    "        \n",
    "        coords_to_pdb(pred['coords'], seq, pdb_path)\n",
    "        energy_minimize(pdb_path, relax_path)\n",
    "        \n",
    "        minimized[target_id].append({\n",
    "            'coords': pred['coords'],\n",
    "            'source': pred['source'],\n",
    "            'seed': pred['seed']\n",
    "        })\n",
    "\n",
    "print(f\"Minimization completed: {len(minimized)} targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Diverse Ensemble Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def load_coords(pdb_path):\n",
    "    \"\"\"Load C1' coordinates from PDB.\"\"\"\n",
    "    coords = []\n",
    "    with open(pdb_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('ATOM') and \"C1'\" in line:\n",
    "                coords.append([float(line[30:38]), float(line[38:46]), float(line[46:54])])\n",
    "    return np.array(coords) if coords else None\n",
    "\n",
    "def compute_rmsd(c1, c2):\n",
    "    if c1 is None or c2 is None or len(c1) != len(c2):\n",
    "        return 100.0\n",
    "    return np.sqrt(np.mean(np.sum((c1-c2)**2, axis=1)))\n",
    "\n",
    "def select_diverse(predictions, n=5):\n",
    "    \"\"\"Select diverse predictions via clustering.\"\"\"\n",
    "    if len(predictions) <= n:\n",
    "        return predictions\n",
    "    \n",
    "    # RMSD matrix\n",
    "    coords = [p['coords'] for p in predictions]\n",
    "    m = len(predictions)\n",
    "    rmsd_mat = np.zeros((m, m))\n",
    "    for i in range(m):\n",
    "        for j in range(i+1, m):\n",
    "            r = compute_rmsd(coords[i], coords[j])\n",
    "            rmsd_mat[i,j] = rmsd_mat[j,i] = r\n",
    "    \n",
    "    try:\n",
    "        Z = linkage(pdist(rmsd_mat), method='complete')\n",
    "        clusters = fcluster(Z, t=n, criterion='maxclust')\n",
    "        \n",
    "        selected = []\n",
    "        for c in range(1, n+1):\n",
    "            members = [i for i, cl in enumerate(clusters) if cl == c]\n",
    "            if members:\n",
    "                selected.append(predictions[members[0]])\n",
    "        \n",
    "        while len(selected) < n:\n",
    "            selected.append(predictions[len(selected) % len(predictions)])\n",
    "        \n",
    "        return selected[:n]\n",
    "    except:\n",
    "        return predictions[:n]\n",
    "\n",
    "# Select ensembles\n",
    "ensembles = {}\n",
    "for target_id in tqdm(test_seqs['target_id'], desc=\"Ensemble\"):\n",
    "    all_preds = []\n",
    "    \n",
    "    if target_id in minimized:\n",
    "        all_preds.extend(minimized[target_id])\n",
    "    \n",
    "    if target_id in drfold2_predictions:\n",
    "        coords = load_coords(drfold2_predictions[target_id])\n",
    "        if coords is not None:\n",
    "            all_preds.append({'coords': coords, 'source': 'drfold2'})\n",
    "    \n",
    "    ensembles[target_id] = select_diverse(all_preds) if all_preds else []\n",
    "\n",
    "print(f\"Ensembles created: {len(ensembles)} targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rows = []\n",
    "\n",
    "for _, row in tqdm(sample_sub.iterrows(), total=len(sample_sub), desc=\"Building\"):\n",
    "    parts = row['ID'].rsplit('_', 1)\n",
    "    target_id = parts[0]\n",
    "    res_idx = int(parts[1]) - 1\n",
    "    \n",
    "    new_row = {'ID': row['ID'], 'resname': row['resname'], 'resid': row['resid']}\n",
    "    ensemble = ensembles.get(target_id, [])\n",
    "    \n",
    "    for model_idx in range(1, 6):\n",
    "        if model_idx <= len(ensemble):\n",
    "            coords = ensemble[model_idx-1].get('coords')\n",
    "            if coords is not None and res_idx < len(coords):\n",
    "                x, y, z = coords[res_idx]\n",
    "            else:\n",
    "                x, y, z = 0.0, 0.0, 0.0\n",
    "        elif len(ensemble) > 0:\n",
    "            coords = ensemble[-1].get('coords')\n",
    "            if coords is not None and res_idx < len(coords):\n",
    "                x, y, z = coords[res_idx]\n",
    "            else:\n",
    "                x, y, z = 0.0, 0.0, 0.0\n",
    "        else:\n",
    "            x, y, z = 0.0, 0.0, 0.0\n",
    "        \n",
    "        new_row[f'x_{model_idx}'] = round(float(x), 3)\n",
    "        new_row[f'y_{model_idx}'] = round(float(y), 3)\n",
    "        new_row[f'z_{model_idx}'] = round(float(z), 3)\n",
    "    \n",
    "    submission_rows.append(new_row)\n",
    "\n",
    "submission = pd.DataFrame(submission_rows)\n",
    "cols = ['ID', 'resname', 'resid'] + [f'{c}_{i}' for i in range(1,6) for c in ['x','y','z']]\n",
    "submission = submission[cols]\n",
    "\n",
    "print(f\"Submission shape: {submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "assert len(submission) == len(sample_sub), \"Row count mismatch!\"\n",
    "assert not submission.isnull().any().any(), \"Contains NaN!\"\n",
    "\n",
    "non_zero = (submission['x_1'] != 0).sum()\n",
    "print(f\"Non-zero predictions: {non_zero}/{len(submission)} ({100*non_zero/len(submission):.1f}%)\")\n",
    "\n",
    "# Save\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSaved submission.csv\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Download `submission.csv` and submit to the competition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
